决策树是一个非参数的监督式学习方法，主要用于分类和回归，算法的目标是通过推断数据特征，学习决策规则从而创建一个预测目标变量的模型。
决策树（Decision Tree）是一种简单但是广泛使用的分类器。通过训练数据构建决策树，可以高效的对未知的数据进行分类。
决策数优点：
决策树模型可以读性好，具有描述性，有助于人工分析；
效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。
决策树既可以做分类，也可以做回归。

参考链接:https://lz5z.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/